{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6adf781a",
   "metadata": {},
   "source": [
    "# Level-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe04a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Compute the frame differences\n",
    "def frame_diff(prev_frame, cur_frame, next_frame):\n",
    "    # Difference between the current frame and the next frame\n",
    "    diff_frames_1 = cv2.absdiff(next_frame, cur_frame)\n",
    "\n",
    "    # Difference between the current frame and the previous frame\n",
    "    diff_frames_2 = cv2.absdiff(cur_frame, prev_frame)\n",
    "\n",
    "    return cv2.bitwise_and(diff_frames_1, diff_frames_2)\n",
    "\n",
    "# Define a function to get the current frame from the webcam\n",
    "def get_frame(cap, scaling_factor):\n",
    "    # Read the current frame from the video capture object\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Resize the image\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, \n",
    "            fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    return gray \n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Define the video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Define the scaling factor for the images\n",
    "    scaling_factor = 0.5\n",
    "    \n",
    "    # Grab the current frame\n",
    "    prev_frame = get_frame(cap, scaling_factor) \n",
    "\n",
    "    # Grab the next frame\n",
    "    cur_frame = get_frame(cap, scaling_factor) \n",
    "\n",
    "    # Grab the frame after that\n",
    "    next_frame = get_frame(cap, scaling_factor) \n",
    "\n",
    "    # Keep reading the frames from the webcam \n",
    "    # until the user hits the 'Esc' key\n",
    "    while True:\n",
    "        # Display the frame difference\n",
    "        cv2.imshow('Object Movement', frame_diff(prev_frame, \n",
    "                cur_frame, next_frame))\n",
    "\n",
    "        # Update the variables\n",
    "        prev_frame = cur_frame\n",
    "        cur_frame = next_frame \n",
    "\n",
    "        # Grab the next frame\n",
    "        next_frame = get_frame(cap, scaling_factor)\n",
    "\n",
    "        # Check if the user hit the 'Esc' key\n",
    "        key = cv2.waitKey(10)\n",
    "        if key == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    # Close all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a9e53c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8bab83d",
   "metadata": {},
   "source": [
    "# Level-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d02d5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to get the current frame from the webcam\n",
    "def get_frame(cap, scaling_factor):\n",
    "    # Read the current frame from the video capture object\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Resize the image\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, \n",
    "            fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return frame\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Define the video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Define the scaling factor for the images\n",
    "    scaling_factor = 0.5\n",
    "\n",
    "    # Keep reading the frames from the webcam \n",
    "    # until the user hits the 'Esc' key\n",
    "    while True:\n",
    "        # Grab the current frame\n",
    "        frame = get_frame(cap, scaling_factor) \n",
    "\n",
    "        # Convert the image to HSV colorspace\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define range of skin color in HSV\n",
    "        lower = np.array([0, 70, 60])\n",
    "        upper = np.array([50, 150, 255])\n",
    "\n",
    "        # Threshold the HSV image to get only skin color\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "        # Bitwise-AND between the mask and original image\n",
    "        img_bitwise_and = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "        # Run median blurring\n",
    "        img_median_blurred = cv2.medianBlur(img_bitwise_and, 5)\n",
    "\n",
    "        # Display the input and output\n",
    "        cv2.imshow('Input', frame)\n",
    "        cv2.imshow('Output', img_median_blurred)\n",
    "\n",
    "        # Check if the user hit the 'Esc' key\n",
    "        c = cv2.waitKey(5) \n",
    "        if c == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    # Close all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3def2660",
   "metadata": {},
   "source": [
    "# Level-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1786de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define a function to get the current frame from the webcam\n",
    "def get_frame(cap, scaling_factor):\n",
    "    # Read the current frame from the video capture object\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Resize the image\n",
    "    frame = cv2.resize(frame, None, fx=scaling_factor, \n",
    "            fy=scaling_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    return frame\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Define the video capture object\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Define the background subtractor object\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "     \n",
    "    \n",
    "    history = 100\n",
    "\n",
    "    # Define the learning rate\n",
    "    learning_rate = 1.0/history\n",
    "\n",
    "    # Keep reading the frames from the webcam \n",
    "    # until the user hits the 'Esc' key\n",
    "    while True:\n",
    "        # Grab the current frame\n",
    "        frame = get_frame(cap, 0.5)\n",
    "\n",
    "        # Compute the mask \n",
    "        mask = bg_subtractor.apply(frame, learningRate=learning_rate)\n",
    "\n",
    "        # Convert grayscale image to RGB color image\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Display the images\n",
    "        cv2.imshow('Input', frame)\n",
    "        cv2.imshow('Output', mask & frame)\n",
    "\n",
    "        # Check if the user hit the 'Esc' key\n",
    "        c = cv2.waitKey(10)\n",
    "        if c == 27:\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    \n",
    "    # Close all the windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846c148",
   "metadata": {},
   "source": [
    "# Level-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01c1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define a class to handle object tracking related functionality\n",
    "class ObjectTracker(object):\n",
    "    def __init__(self, scaling_factor=0.5):\n",
    "        # Initialize the video capture object\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Capture the frame from the webcam\n",
    "        _, self.frame = self.cap.read()\n",
    "\n",
    "        # Scaling factor for the captured frame\n",
    "        self.scaling_factor = scaling_factor\n",
    "\n",
    "        # Resize the frame\n",
    "        self.frame = cv2.resize(self.frame, None,fx=self.scaling_factor, fy=self.scaling_factor, \n",
    "                                interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Create a window to display the frame\n",
    "        cv2.namedWindow('Object Tracker')\n",
    "\n",
    "        # Set the mouse callback function to track the mouse\n",
    "        cv2.setMouseCallback('Object Tracker', self.mouse_event)\n",
    "\n",
    "        # Initialize variable related to rectangular region selection\n",
    "        self.selection = None\n",
    "\n",
    "        # Initialize variable related to starting position \n",
    "        self.drag_start = None\n",
    "\n",
    "        # Initialize variable related to the state of tracking \n",
    "        self.tracking_state = 0\n",
    "\n",
    "    # Define a method to track the mouse events\n",
    "    def mouse_event(self, event, x, y, flags, param):\n",
    "        # Convert x and y coordinates into 16-bit numpy integers\n",
    "        x, y = np.int16([x, y]) \n",
    "\n",
    "        # Check if a mouse button down event has occurred\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drag_start = (x, y)\n",
    "            self.tracking_state = 0\n",
    "\n",
    "        # Check if the user has started selecting the region\n",
    "        if self.drag_start:\n",
    "            if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "                # Extract the dimensions of the frame\n",
    "                h, w = self.frame.shape[:2]\n",
    "\n",
    "                # Get the initial position\n",
    "                xi, yi = self.drag_start\n",
    "\n",
    "                # Get the max and min values\n",
    "                x0, y0 = np.maximum(0, np.minimum([xi, yi], [x, y]))\n",
    "                x1, y1 = np.minimum([w, h], np.maximum([xi, yi], [x, y]))\n",
    "\n",
    "                # Reset the selection variable\n",
    "                self.selection = None\n",
    "\n",
    "                # Finalize the rectangular selection\n",
    "                if x1-x0 > 0 and y1-y0 > 0:\n",
    "                    self.selection = (x0, y0, x1, y1)\n",
    "\n",
    "            else:\n",
    "                # If the selection is done, start tracking  \n",
    "                self.drag_start = None\n",
    "                if self.selection is not None:\n",
    "                    self.tracking_state = 1\n",
    "\n",
    "    # Method to start tracking the object\n",
    "    def start_tracking(self):\n",
    "        # Iterate until the user presses the Esc key\n",
    "        while True:\n",
    "            # Capture the frame from webcam\n",
    "            _, self.frame = self.cap.read()\n",
    "            \n",
    "            # Resize the input frame\n",
    "            self.frame = cv2.resize(self.frame, None, \n",
    "                    fx=self.scaling_factor, fy=self.scaling_factor, \n",
    "                    interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Create a copy of the frame\n",
    "            vis = self.frame.copy()\n",
    "\n",
    "            # Convert the frame to HSV colorspace\n",
    "            hsv = cv2.cvtColor(self.frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Create the mask based on predefined thresholds\n",
    "            mask = cv2.inRange(hsv, np.array((0., 60., 32.)), \n",
    "                        np.array((180., 255., 255.)))\n",
    "\n",
    "            # Check if the user has selected the region\n",
    "            if self.selection:\n",
    "                # Extract the coordinates of the selected rectangle\n",
    "                x0, y0, x1, y1 = self.selection\n",
    "\n",
    "                # Extract the tracking window\n",
    "                self.track_window = (x0, y0, x1-x0, y1-y0)\n",
    "\n",
    "                # Extract the regions of interest \n",
    "                hsv_roi = hsv[y0:y1, x0:x1]\n",
    "                mask_roi = mask[y0:y1, x0:x1]\n",
    "\n",
    "                # Compute the histogram of the region of \n",
    "                # interest in the HSV image using the mask\n",
    "                hist = cv2.calcHist( [hsv_roi], [0], mask_roi, \n",
    "                        [16], [0, 180] )\n",
    "\n",
    "                # Normalize and reshape the histogram\n",
    "                cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX);\n",
    "                self.hist = hist.reshape(-1)\n",
    "\n",
    "                # Extract the region of interest from the frame\n",
    "                vis_roi = vis[y0:y1, x0:x1]\n",
    "\n",
    "                # Compute the image negative (for display only)\n",
    "                cv2.bitwise_not(vis_roi, vis_roi)\n",
    "                vis[mask == 0] = 0\n",
    "\n",
    "            # Check if the system in the \"tracking\" mode\n",
    "            if self.tracking_state == 1:\n",
    "                # Reset the selection variable\n",
    "                self.selection = None\n",
    "                \n",
    "                # Compute the histogram back projection\n",
    "                hsv_backproj = cv2.calcBackProject([hsv], [0], \n",
    "                        self.hist, [0, 180], 1)\n",
    "\n",
    "                # Compute bitwise AND between histogram \n",
    "                # backprojection and the mask\n",
    "                hsv_backproj &= mask\n",
    "\n",
    "                # Define termination criteria for the tracker\n",
    "                term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                        10, 1)\n",
    "\n",
    "                # Apply CAMShift on 'hsv_backproj'\n",
    "                track_box, self.track_window = cv2.CamShift(hsv_backproj, \n",
    "                        self.track_window, term_crit)\n",
    "\n",
    "                # Draw an ellipse around the object\n",
    "                cv2.ellipse(vis, track_box, (0, 255, 0), 2)\n",
    "\n",
    "            # Show the output live video\n",
    "            cv2.imshow('Object Tracker', vis)\n",
    "\n",
    "            # Stop if the user hits the 'Esc' key\n",
    "            c = cv2.waitKey(5)\n",
    "            if c == 27:\n",
    "                break\n",
    "        self.cap.release()\n",
    "\n",
    "        # Close all the windows\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# Start the tracker\n",
    "    ObjectTracker().start_tracking()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc7605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc1c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
