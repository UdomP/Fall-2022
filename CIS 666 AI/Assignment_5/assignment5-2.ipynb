{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import deque\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10-07-2015</td>\n",
       "      <td>262.220001</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>257.820007</td>\n",
       "      <td>259.149994</td>\n",
       "      <td>259.149994</td>\n",
       "      <td>2610900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13-07-2015</td>\n",
       "      <td>262.250000</td>\n",
       "      <td>262.549988</td>\n",
       "      <td>256.049988</td>\n",
       "      <td>262.160004</td>\n",
       "      <td>262.160004</td>\n",
       "      <td>2960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14-07-2015</td>\n",
       "      <td>262.100006</td>\n",
       "      <td>265.989990</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>265.649994</td>\n",
       "      <td>265.649994</td>\n",
       "      <td>1907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15-07-2015</td>\n",
       "      <td>266.739990</td>\n",
       "      <td>267.489990</td>\n",
       "      <td>262.079987</td>\n",
       "      <td>263.140015</td>\n",
       "      <td>263.140015</td>\n",
       "      <td>2021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-07-2015</td>\n",
       "      <td>264.220001</td>\n",
       "      <td>267.200012</td>\n",
       "      <td>263.160004</td>\n",
       "      <td>266.679993</td>\n",
       "      <td>266.679993</td>\n",
       "      <td>1616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>28-01-2020</td>\n",
       "      <td>568.489990</td>\n",
       "      <td>576.809998</td>\n",
       "      <td>558.080017</td>\n",
       "      <td>566.900024</td>\n",
       "      <td>566.900024</td>\n",
       "      <td>11788500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>29-01-2020</td>\n",
       "      <td>575.690002</td>\n",
       "      <td>589.799988</td>\n",
       "      <td>567.429993</td>\n",
       "      <td>580.989990</td>\n",
       "      <td>580.989990</td>\n",
       "      <td>17801500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>30-01-2020</td>\n",
       "      <td>632.419983</td>\n",
       "      <td>650.880005</td>\n",
       "      <td>618.000000</td>\n",
       "      <td>640.809998</td>\n",
       "      <td>640.809998</td>\n",
       "      <td>29005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>31-01-2020</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>632.520020</td>\n",
       "      <td>650.570007</td>\n",
       "      <td>650.570007</td>\n",
       "      <td>15719300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>03-02-2020</td>\n",
       "      <td>673.690002</td>\n",
       "      <td>786.140015</td>\n",
       "      <td>673.520020</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>780.000000</td>\n",
       "      <td>47065000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     10-07-2015  262.220001  263.000000  257.820007  259.149994  259.149994   \n",
       "1     13-07-2015  262.250000  262.549988  256.049988  262.160004  262.160004   \n",
       "2     14-07-2015  262.100006  265.989990  260.510010  265.649994  265.649994   \n",
       "3     15-07-2015  266.739990  267.489990  262.079987  263.140015  263.140015   \n",
       "4     16-07-2015  264.220001  267.200012  263.160004  266.679993  266.679993   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1145  28-01-2020  568.489990  576.809998  558.080017  566.900024  566.900024   \n",
       "1146  29-01-2020  575.690002  589.799988  567.429993  580.989990  580.989990   \n",
       "1147  30-01-2020  632.419983  650.880005  618.000000  640.809998  640.809998   \n",
       "1148  31-01-2020  640.000000  653.000000  632.520020  650.570007  650.570007   \n",
       "1149  03-02-2020  673.690002  786.140015  673.520020  780.000000  780.000000   \n",
       "\n",
       "        Volume  \n",
       "0      2610900  \n",
       "1      2960300  \n",
       "2      1907600  \n",
       "3      2021600  \n",
       "4      1616000  \n",
       "...        ...  \n",
       "1145  11788500  \n",
       "1146  17801500  \n",
       "1147  29005700  \n",
       "1148  15719300  \n",
       "1149  47065000  \n",
       "\n",
       "[1150 rows x 7 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TSLA.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# df['Close'] = scaler.fit_transform(np.expand_dims(df['Close'].values, axis=1))\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Close']]\n",
    "X = df.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)\n",
    "# X = X.values.reshape((None, ))\n",
    "\n",
    "# X['Volume'] = X['Volume'].astype('float32') / 255\n",
    "X['Date'] = df.index\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Date       Close\n",
       " 1040  1040  214.080002\n",
       " 717    717  284.179993\n",
       " 187    187  257.200012\n",
       " 3        3  263.140015\n",
       " 433    433  277.380005\n",
       " ...    ...         ...\n",
       " 1115  1115  359.679993\n",
       " 414    414  250.479996\n",
       " 70      70  228.100006\n",
       " 830    830  288.500000\n",
       " 236    236  217.929993\n",
       " \n",
       " [920 rows x 2 columns],\n",
       "      Date       Close\n",
       " 297   297  196.050003\n",
       " 858   858  359.700012\n",
       " 757   757  316.709991\n",
       " 601   601  316.809998\n",
       " 272   272  226.160004\n",
       " ..    ...         ...\n",
       " 378   378  231.279999\n",
       " 325   325  200.089996\n",
       " 330   330  199.970001\n",
       " 134   134  199.970001\n",
       " 177   177  222.580002\n",
       " \n",
       " [230 rows x 2 columns],\n",
       "            Close\n",
       " 1040  214.080002\n",
       " 717   284.179993\n",
       " 187   257.200012\n",
       " 3     263.140015\n",
       " 433   277.380005\n",
       " ...          ...\n",
       " 1115  359.679993\n",
       " 414   250.479996\n",
       " 70    228.100006\n",
       " 830   288.500000\n",
       " 236   217.929993\n",
       " \n",
       " [920 rows x 1 columns],\n",
       "           Close\n",
       " 297  196.050003\n",
       " 858  359.700012\n",
       " 757  316.709991\n",
       " 601  316.809998\n",
       " 272  226.160004\n",
       " ..          ...\n",
       " 378  231.279999\n",
       " 325  200.089996\n",
       " 330  199.970001\n",
       " 134  199.970001\n",
       " 177  222.580002\n",
       " \n",
       " [230 rows x 1 columns])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=2, activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# model.add(LSTM(60, return_sequences=True, input_shape=(10, 3)))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(120, return_sequences=False))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(Dense(20))\n",
    "# model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 [==============================] - 3s 5ms/step - loss: 4480.1436 - accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 4050.1106 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3738.7678 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3452.7827 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3332.8640 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3282.0867 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3198.6255 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3280.2891 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 1s 5ms/step - loss: 3302.8684 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3271.4648 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3244.2961 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3129.0837 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3292.6375 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3252.5210 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3196.1023 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3215.4353 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3220.5376 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3260.6013 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3129.8953 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3160.0557 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3163.9980 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3300.3508 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3192.6208 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3202.3928 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3174.1677 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3301.4561 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3293.7554 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3176.7649 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3157.3721 - accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3199.4766 - accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3191.8164 - accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3188.9336 - accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3201.0747 - accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3182.8025 - accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3180.6592 - accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3232.2004 - accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3172.5559 - accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3156.0786 - accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3248.2817 - accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3203.0779 - accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3101.0530 - accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3218.4590 - accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3128.4949 - accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3151.4463 - accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 0s 4ms/step - loss: 3309.8040 - accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3134.6948 - accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3201.8535 - accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3118.8423 - accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3063.2141 - accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3146.6216 - accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3167.3835 - accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3117.9932 - accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3180.5002 - accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3162.5886 - accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3267.5122 - accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3266.2932 - accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3179.8525 - accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3185.8513 - accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3330.7844 - accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3182.0623 - accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3149.2878 - accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3137.7375 - accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3132.2258 - accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3161.3779 - accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3233.2400 - accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3138.1289 - accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3117.2327 - accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3160.6201 - accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3223.8516 - accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3363.7241 - accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3080.2847 - accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3139.1614 - accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3185.3467 - accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3201.5747 - accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3155.6660 - accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3144.5398 - accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3325.6594 - accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3217.5549 - accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3226.1470 - accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3037.1140 - accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3187.4277 - accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3228.4822 - accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3162.3577 - accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3197.0071 - accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3067.8223 - accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3109.3921 - accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3085.5527 - accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3150.2556 - accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3078.6736 - accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3049.0059 - accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3057.9368 - accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 1s 9ms/step - loss: 3064.8071 - accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 1s 7ms/step - loss: 3165.4453 - accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 1s 8ms/step - loss: 3105.6313 - accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3102.5427 - accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3075.2698 - accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 2961.1899 - accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3010.2327 - accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 1s 6ms/step - loss: 3001.9597 - accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 0s 5ms/step - loss: 3144.6746 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ee35686d0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 4ms/step - loss: 4684.2310 - accuracy: 0.0000e+00\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "print('Accuracy:', (100.0 * acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
