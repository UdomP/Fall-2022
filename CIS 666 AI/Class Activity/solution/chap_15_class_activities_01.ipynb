{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81b7b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize, WordPunctTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec52c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('Language_data.txt','r',errors='ignore')\n",
    "input_text=f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4bcf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence tokenizer:\n",
      "['Attracting and retaining the mindshare of your customer base is a challenge that most enterprises are constantly struggling with.', 'To improve your brand recall, you need to constantly generate quality content that is relevant and engaging and properly appropriated for circulation in a variety of outlets.', 'Here comes Generative AI, which offers new capabilities to augment content creation.', 'Using generative AI, Enterprises can create a variety of content like images, videos, and written material and decrease turnaround time.']\n",
      "\n",
      "Word tokenizer:\n",
      "['Attracting', 'and', 'retaining', 'the', 'mindshare', 'of', 'your', 'customer', 'base', 'is', 'a', 'challenge', 'that', 'most', 'enterprises', 'are', 'constantly', 'struggling', 'with', '.', 'To', 'improve', 'your', 'brand', 'recall', ',', 'you', 'need', 'to', 'constantly', 'generate', 'quality', 'content', 'that', 'is', 'relevant', 'and', 'engaging', 'and', 'properly', 'appropriated', 'for', 'circulation', 'in', 'a', 'variety', 'of', 'outlets', '.', 'Here', 'comes', 'Generative', 'AI', ',', 'which', 'offers', 'new', 'capabilities', 'to', 'augment', 'content', 'creation', '.', 'Using', 'generative', 'AI', ',', 'Enterprises', 'can', 'create', 'a', 'variety', 'of', 'content', 'like', 'images', ',', 'videos', ',', 'and', 'written', 'material', 'and', 'decrease', 'turnaround', 'time', '.']\n",
      "\n",
      "Word punct tokenizer:\n",
      "['Attracting', 'and', 'retaining', 'the', 'mindshare', 'of', 'your', 'customer', 'base', 'is', 'a', 'challenge', 'that', 'most', 'enterprises', 'are', 'constantly', 'struggling', 'with', '.', 'To', 'improve', 'your', 'brand', 'recall', ',', 'you', 'need', 'to', 'constantly', 'generate', 'quality', 'content', 'that', 'is', 'relevant', 'and', 'engaging', 'and', 'properly', 'appropriated', 'for', 'circulation', 'in', 'a', 'variety', 'of', 'outlets', '.', 'Here', 'comes', 'Generative', 'AI', ',', 'which', 'offers', 'new', 'capabilities', 'to', 'augment', 'content', 'creation', '.', 'Using', 'generative', 'AI', ',', 'Enterprises', 'can', 'create', 'a', 'variety', 'of', 'content', 'like', 'images', ',', 'videos', ',', 'and', 'written', 'material', 'and', 'decrease', 'turnaround', 'time', '.']\n"
     ]
    }
   ],
   "source": [
    "# Sentence tokenizer \n",
    "print(\"\\nSentence tokenizer:\")\n",
    "print(sent_tokenize(input_text))\n",
    "\n",
    "# Word tokenizer\n",
    "print(\"\\nWord tokenizer:\")\n",
    "df=word_tokenize(input_text)\n",
    "print(df)\n",
    "\n",
    "# WordPunct tokenizer\n",
    "print(\"\\nWord punct tokenizer:\")\n",
    "print(WordPunctTokenizer().tokenize(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9515ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               INPUT WORD         NOUN LEMMATIZER         VERB LEMMATIZER \n",
      " ===========================================================================\n",
      "              Attracting              Attracting              Attracting\n",
      "                     and                     and                     and\n",
      "               retaining               retaining                  retain\n",
      "                     the                     the                     the\n",
      "               mindshare               mindshare               mindshare\n",
      "                      of                      of                      of\n",
      "                    your                    your                    your\n",
      "                customer                customer                customer\n",
      "                    base                    base                    base\n",
      "                      is                      is                      be\n",
      "                       a                       a                       a\n",
      "               challenge               challenge               challenge\n",
      "                    that                    that                    that\n",
      "                    most                    most                    most\n",
      "             enterprises              enterprise             enterprises\n",
      "                     are                     are                      be\n",
      "              constantly              constantly              constantly\n",
      "              struggling              struggling                struggle\n",
      "                    with                    with                    with\n",
      "                       .                       .                       .\n",
      "                      To                      To                      To\n",
      "                 improve                 improve                 improve\n",
      "                    your                    your                    your\n",
      "                   brand                   brand                   brand\n",
      "                  recall                  recall                  recall\n",
      "                       ,                       ,                       ,\n",
      "                     you                     you                     you\n",
      "                    need                    need                    need\n",
      "                      to                      to                      to\n",
      "              constantly              constantly              constantly\n",
      "                generate                generate                generate\n",
      "                 quality                 quality                 quality\n",
      "                 content                 content                 content\n",
      "                    that                    that                    that\n",
      "                      is                      is                      be\n",
      "                relevant                relevant                relevant\n",
      "                     and                     and                     and\n",
      "                engaging                engaging                  engage\n",
      "                     and                     and                     and\n",
      "                properly                properly                properly\n",
      "            appropriated            appropriated             appropriate\n",
      "                     for                     for                     for\n",
      "             circulation             circulation             circulation\n",
      "                      in                      in                      in\n",
      "                       a                       a                       a\n",
      "                 variety                 variety                 variety\n",
      "                      of                      of                      of\n",
      "                 outlets                  outlet                 outlets\n",
      "                       .                       .                       .\n",
      "                    Here                    Here                    Here\n",
      "                   comes                    come                    come\n",
      "              Generative              Generative              Generative\n",
      "                      AI                      AI                      AI\n",
      "                       ,                       ,                       ,\n",
      "                   which                   which                   which\n",
      "                  offers                   offer                   offer\n",
      "                     new                     new                     new\n",
      "            capabilities              capability            capabilities\n",
      "                      to                      to                      to\n",
      "                 augment                 augment                 augment\n",
      "                 content                 content                 content\n",
      "                creation                creation                creation\n",
      "                       .                       .                       .\n",
      "                   Using                   Using                   Using\n",
      "              generative              generative              generative\n",
      "                      AI                      AI                      AI\n",
      "                       ,                       ,                       ,\n",
      "             Enterprises             Enterprises             Enterprises\n",
      "                     can                     can                     can\n",
      "                  create                  create                  create\n",
      "                       a                       a                       a\n",
      "                 variety                 variety                 variety\n",
      "                      of                      of                      of\n",
      "                 content                 content                 content\n",
      "                    like                    like                    like\n",
      "                  images                   image                   image\n",
      "                       ,                       ,                       ,\n",
      "                  videos                   video                  videos\n",
      "                       ,                       ,                       ,\n",
      "                     and                     and                     and\n",
      "                 written                 written                   write\n",
      "                material                material                material\n",
      "                     and                     and                     and\n",
      "                decrease                decrease                decrease\n",
      "              turnaround              turnaround              turnaround\n",
      "                    time                    time                    time\n",
      "                       .                       .                       .\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Create a list of lemmatizer names for display\n",
    "lemmatizer_names = ['NOUN LEMMATIZER', 'VERB LEMMATIZER']\n",
    "formatted_text = '{:>24}' * (len(lemmatizer_names) + 1)\n",
    "print('\\n', formatted_text.format('INPUT WORD', *lemmatizer_names), '\\n', '='*75)\n",
    "\n",
    "# Lemmatize each word and display the output\n",
    "for word in df:\n",
    "    output = [word, lemmatizer.lemmatize(word, pos='n'),\n",
    "           lemmatizer.lemmatize(word, pos='v')]\n",
    "    print(formatted_text.format(*output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d3b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       INPUT WORD          PORTER       LANCASTER        SNOWBALL \n",
      " ====================================================================\n",
      "      Attracting         attract         attract         attract\n",
      "             and             and             and             and\n",
      "       retaining          retain          retain          retain\n",
      "             the             the             the             the\n",
      "       mindshare        mindshar          mindsh        mindshar\n",
      "              of              of              of              of\n",
      "            your            your              yo            your\n",
      "        customer          custom          custom          custom\n",
      "            base            base             bas            base\n",
      "              is              is              is              is\n",
      "               a               a               a               a\n",
      "       challenge        challeng        challeng        challeng\n",
      "            that            that            that            that\n",
      "            most            most            most            most\n",
      "     enterprises       enterpris         enterpr       enterpris\n",
      "             are             are              ar             are\n",
      "      constantly      constantli           const        constant\n",
      "      struggling         struggl      struggling         struggl\n",
      "            with            with            with            with\n",
      "               .               .               .               .\n",
      "              To              to              to              to\n",
      "         improve          improv          improv          improv\n",
      "            your            your              yo            your\n",
      "           brand           brand           brand           brand\n",
      "          recall           recal           recal           recal\n",
      "               ,               ,               ,               ,\n",
      "             you             you             you             you\n",
      "            need            need             nee            need\n",
      "              to              to              to              to\n",
      "      constantly      constantli           const        constant\n",
      "        generate           gener             gen         generat\n",
      "         quality         qualiti            qual         qualiti\n",
      "         content         content            cont         content\n",
      "            that            that            that            that\n",
      "              is              is              is              is\n",
      "        relevant           relev           relev           relev\n",
      "             and             and             and             and\n",
      "        engaging           engag             eng           engag\n",
      "             and             and             and             and\n",
      "        properly        properli            prop          proper\n",
      "    appropriated        appropri        appropry        appropri\n",
      "             for             for             for             for\n",
      "     circulation          circul            circ          circul\n",
      "              in              in              in              in\n",
      "               a               a               a               a\n",
      "         variety         varieti            vary         varieti\n",
      "              of              of              of              of\n",
      "         outlets          outlet          outlet          outlet\n",
      "               .               .               .               .\n",
      "            Here            here             her            here\n",
      "           comes            come             com            come\n",
      "      Generative           gener             gen         generat\n",
      "              AI              ai              ai              ai\n",
      "               ,               ,               ,               ,\n",
      "           which           which           which           which\n",
      "          offers           offer             off           offer\n",
      "             new             new             new             new\n",
      "    capabilities          capabl             cap          capabl\n",
      "              to              to              to              to\n",
      "         augment         augment             aug         augment\n",
      "         content         content            cont         content\n",
      "        creation        creation             cre        creation\n",
      "               .               .               .               .\n",
      "           Using             use              us             use\n",
      "      generative           gener             gen         generat\n",
      "              AI              ai              ai              ai\n",
      "               ,               ,               ,               ,\n",
      "     Enterprises       enterpris         enterpr       enterpris\n",
      "             can             can             can             can\n",
      "          create           creat             cre           creat\n",
      "               a               a               a               a\n",
      "         variety         varieti            vary         varieti\n",
      "              of              of              of              of\n",
      "         content         content            cont         content\n",
      "            like            like             lik            like\n",
      "          images            imag              im            imag\n",
      "               ,               ,               ,               ,\n",
      "          videos           video           video           video\n",
      "               ,               ,               ,               ,\n",
      "             and             and             and             and\n",
      "         written         written            writ         written\n",
      "        material          materi             mat          materi\n",
      "             and             and             and             and\n",
      "        decrease         decreas         decreas         decreas\n",
      "      turnaround      turnaround      turnaround      turnaround\n",
      "            time            time             tim            time\n",
      "               .               .               .               .\n"
     ]
    }
   ],
   "source": [
    "# Create various stemmer objects\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "\n",
    "# Create a list of stemmer names for display\n",
    "stemmer_names = ['PORTER', 'LANCASTER', 'SNOWBALL']\n",
    "formatted_text = '{:>16}' * (len(stemmer_names) + 1)\n",
    "print('\\n', formatted_text.format('INPUT WORD', *stemmer_names), '\\n', '='*68)\n",
    "\n",
    "# Stem each word and display the output\n",
    "for word in df:\n",
    "    output = [word, porter.stem(word), lancaster.stem(word), snowball.stem(word)]\n",
    "    print(formatted_text.format(*output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecac31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of text chunks = 9 \n",
      "\n",
      "Chunk 1 ==> Attracting and retaining the mindshare of your customer base is\n",
      "Chunk 2 ==> a challenge that most enterprises are constantly struggling with .\n",
      "Chunk 3 ==> To improve your brand recall , you need to constantly\n",
      "Chunk 4 ==> generate quality content that is relevant and engaging and properly\n",
      "Chunk 5 ==> appropriated for circulation in a variety of outlets . Here\n",
      "Chunk 6 ==> comes Generative AI , which offers new capabilities to augment\n",
      "Chunk 7 ==> content creation . Using generative AI , Enterprises can create\n",
      "Chunk 8 ==> a variety of content like images , videos , and\n",
      "Chunk 9 ==> written material and decrease turnaround time .\n"
     ]
    }
   ],
   "source": [
    "def chunker(input_data, N):\n",
    "    output = []\n",
    "\n",
    "    cur_chunk = []\n",
    "    count = 0\n",
    "    for word in df:\n",
    "        cur_chunk.append(word)\n",
    "        count += 1\n",
    "        if count == N:\n",
    "            output.append(' '.join(cur_chunk))\n",
    "            count, cur_chunk = 0, []\n",
    "\n",
    "    output.append(' '.join(cur_chunk))\n",
    "\n",
    "    return output \n",
    "\n",
    "if __name__=='__main__':\n",
    "    # Read the first 12000 words from the Brown corpus\n",
    "    #input_data = ' '.join(brown.words()[:12000])\n",
    "\n",
    "    # Define the number of words in each chunk \n",
    "    chunk_size = 10\n",
    "\n",
    "    chunks = chunker(df, chunk_size)\n",
    "    print('\\nNumber of text chunks =', len(chunks), '\\n')\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print('Chunk', i+1, '==>', chunk[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40858f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "f_new=open('BoW_data.txt','r',errors='ignore')\n",
    "input_text_new=f_new.read()\n",
    "df_new=word_tokenize(input_text_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00d8deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(input_data, N):\n",
    "    output = []\n",
    "\n",
    "    cur_chunk = []\n",
    "    count = 0\n",
    "    for word in df_new:\n",
    "        cur_chunk.append(word)\n",
    "        count += 1\n",
    "        if count == N:\n",
    "            output.append(' '.join(cur_chunk))\n",
    "            count, cur_chunk = 0, []\n",
    "\n",
    "    output.append(' '.join(cur_chunk))\n",
    "\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6f75dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary:\n",
      " ['and' 'are' 'for' 'in' 'like' 'models' 'of' 'the' 'to' 'will']\n",
      "\n",
      "Document term matrix:\n",
      "\n",
      "         Word     Chunk-1     Chunk-2     Chunk-3     Chunk-4     Chunk-5     Chunk-6 \n",
      "\n",
      "         and          12          14          10           9          13          11\n",
      "         are           2           3           3           2           1           1\n",
      "         for           4           2           2           4           3           3\n",
      "          in           5           6           7           7           5           4\n",
      "        like           2           1           4           2           1           4\n",
      "      models           2           4           1           2           1           2\n",
      "          of           6           9           7           3           1           1\n",
      "         the           9           9           7          12           9           6\n",
      "          to           5           8           8           6           5           4\n",
      "        will           1           3           3           1          11           5\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 250\n",
    "\n",
    "text_chunks = chunker(df_new, chunk_size)\n",
    "\n",
    "# Convert to dict items\n",
    "chunks = []\n",
    "for count, chunk in enumerate(text_chunks):\n",
    "    d = {'index': count, 'text': chunk}\n",
    "    chunks.append(d)\n",
    "\n",
    "# Extract the document term matrix\n",
    "count_vectorizer = CountVectorizer(min_df=6, max_df=20)\n",
    "document_term_matrix = count_vectorizer.fit_transform([chunk['text'] for chunk in chunks])\n",
    "\n",
    "# Extract the vocabulary and display it\n",
    "vocabulary = np.array(count_vectorizer.get_feature_names())\n",
    "print(\"\\nVocabulary:\\n\", vocabulary)\n",
    "\n",
    "# Generate names for chunks\n",
    "chunk_names = []\n",
    "for i in range(len(text_chunks)):\n",
    "    chunk_names.append('Chunk-' + str(i+1))\n",
    "\n",
    "# Print the document term matrix\n",
    "print(\"\\nDocument term matrix:\")\n",
    "formatted_text = '{:>12}' * (len(chunk_names) + 1)\n",
    "print('\\n', formatted_text.format('Word', *chunk_names), '\\n')\n",
    "for word, item in zip(vocabulary, document_term_matrix.T):\n",
    "    # 'item' is a 'csr_matrix' data structure\n",
    "    output = [word] + [str(freq) for freq in item.data]\n",
    "    print(formatted_text.format(*output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be65624f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94339a27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
